{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80ef78-6755-4e59-914e-437a42a6b683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "#bucket: str for s3 bucket name\n",
    "#get_tokens: if True, gets NER tokens; if False, gets assertions\n",
    "#use_clean: if True, uses cleaned_notes column; if False, uses raw notes colum\n",
    "#import name: str for input file in s3 bucket\n",
    "#export_name: str for beginning exported filenames (do not include '.csv')\n",
    "bucket = \"\"\n",
    "get_tokens = True\n",
    "use_clean = True\n",
    "import_name = \"data/note_set_cleaned.csv\"\n",
    "export_name = \"data/processed_notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9b5c4-e6f4-413b-aabb-2276b408f756",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3_response = s3_client.get_object(\n",
    "    Bucket=bucket,\n",
    "    Key='license/sparknlp_for_healthcare.5.5.1.json'\n",
    ")\n",
    "s3_object_body = s3_response.get('Body')\n",
    "license_keys=json.load(s3_object_body)\n",
    "\n",
    "locals().update(license_keys)\n",
    "\n",
    "# Update specific env variables\n",
    "os.environ.update({ k: license_keys[k] for k in \n",
    "    ( \n",
    "        \"SECRET\",\n",
    "        \"PUBLIC_VERSION\",\n",
    "        \"JSL_VERSION\",\n",
    "        'SPARK_NLP_LICENSE'\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7721dc8-7748-424f-8fa8-89a9f47303b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "%pip install --upgrade -q pyspark==3.4.1 spark-nlp==$PUBLIC_VERSION \n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "%pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
    "\n",
    "# Installing Spark NLP Display Library for visualization\n",
    "%pip install -q spark-nlp-display \n",
    "\n",
    "# svgwrite==1.4\n",
    "# py4j==0.10.9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069745c-2ac9-467c-bc63-8bc26a13423a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sparknlp_jsl\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp_jsl.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47d1ed-d551-4154-adaf-c16243cead65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cpus = os.cpu_count()\n",
    "\n",
    "params_dict = {}\n",
    "params_dict[96] = {\n",
    "    \"spark.network.timeout\": \"600s\",    #default \n",
    "    \"spark.driver.memory\": \"200G\",      #  200G + 172GB <= 384 GB\n",
    "    \"spark.executor.memory\": \"2200M\",\n",
    "    #\"spark.executor.memory\": \"1800M\",     # 96 cores * 1.8GB = ~ 172 GB\n",
    "    \"spark.serializer\": \"org.apache.spark.serializer.KryoSerializer\",\n",
    "    \"spark.kryoserializer.buffer.max\": \"2000M\",\n",
    "    \"spark.driver.maxResultSize\": \"4G\",    # 96 * 2 = 192GB < 200G\n",
    "    #\"spark.memory.offHeap.enabled\": \"true\",\n",
    "}\n",
    "\n",
    "params_dict[48] = {\n",
    "    \"spark.network.timeout\": \"600s\",    #default \n",
    "    \"spark.driver.memory\": \"100G\",      #  100G + 87G <= 192 GB\n",
    "    \"spark.executor.memory\": \"1800M\",     # 48 cores * 1.8GB = ~87 GB\n",
    "    \"spark.serializer\": \"org.apache.spark.serializer.KryoSerializer\",\n",
    "    \"spark.kryoserializer.buffer.max\": \"2000M\",\n",
    "    \"spark.driver.maxResultSize\": \"4G\",    # 48 * 2 = 96GB < 100G\n",
    "    #\"spark.memory.offHeap.enabled\": \"true\",\n",
    "}\n",
    "\n",
    "params_dict[32] = {\n",
    "    \"spark.network.timeout\": \"600s\",    #default \n",
    "    \"spark.driver.memory\": \"100G\",      \n",
    "    \"spark.executor.memory\": \"1800M\",     \n",
    "    \"spark.serializer\": \"org.apache.spark.serializer.KryoSerializer\",\n",
    "    \"spark.kryoserializer.buffer.max\": \"2000M\",\n",
    "    \"spark.driver.maxResultSize\": \"4G\",    \n",
    "    #\"spark.memory.offHeap.enabled\": \"true\",\n",
    "}\n",
    "params = params_dict[num_cpus]\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'], gpu=False, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4bc53-cc14-4103-8ca2-6b11a4e4c1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad226b7-a79c-4fc0-8325-2d8e850d22fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "     .setInputCols([\"document\"])\\\n",
    "     .setOutputCol(\"sentence\")\\\n",
    "     .setCustomBounds([\"  \", \".'\"])\\\n",
    "     .setSplitLength(150)\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07207510-e4d1-4b95-855d-0c2916e2d1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Our three NER models\n",
    "clinical_ner = MedicalNerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"clinical_ner\")\n",
    "\n",
    "wip_ner = MedicalNerModel.pretrained(\"jsl_ner_wip_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"wip_ner\")\n",
    "\n",
    "bert_ner = MedicalBertForTokenClassifier.pretrained(\"bert_token_classifier_ner_jsl\",\n",
    "                                                        \"en\",\n",
    "                                                        \"clinical/models\")\\\n",
    "    .setInputCols(\"token\", \"sentence\")\\\n",
    "    .setOutputCol(\"bert_ner\")\n",
    "\n",
    "clinical_ner_converter = NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"clinical_ner\"]) \\\n",
    "    .setOutputCol(\"clinical_ner_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "wip_ner_converter = NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"wip_ner\"]) \\\n",
    "    .setOutputCol(\"wip_ner_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "bert_ner_converter = NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"bert_ner\"]) \\\n",
    "    .setOutputCol(\"bert_ner_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "#Merger model - when chunks conflict, this one uses the output with the highest confidence score\n",
    "chunk_merger = ChunkMergeApproach()\\\n",
    "    .setInputCols([\"clinical_ner_chunk\", \"wip_ner_chunk\", \"bert_ner_chunk\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setOrderingFeatures([\"ChunkConfidence\"])\\\n",
    "    .setSelectionStrategy(\"Sequential\")\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_assertion = AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09ab37-7065-458c-949b-244c3cb91186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create the pipeline\n",
    "nlpPipeline_difdetect = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    clinical_ner_converter,\n",
    "    wip_ner,\n",
    "    wip_ner_converter,\n",
    "    bert_ner,\n",
    "    bert_ner_converter,\n",
    "    chunk_merger,\n",
    "    clinical_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model_difdetect = nlpPipeline_difdetect.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa5281-b5ab-41ce-a05a-58baa481f073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_clean:\n",
    "    text = pd.read_csv(f\"s3://{bucket}/{import_name}\", usecols=[\"notes_id\", \"cleaned_notes\"] )\n",
    "    text.notes_id = text.notes_id.astype(str)\n",
    "    text = text.drop_duplicates(subset=[\"notes_id\"]).reset_index(drop=True)\n",
    "    text = text.rename(columns={\"cleaned_notes\":\"text\"})\n",
    "else:\n",
    "    text = pd.read_csv(f\"s3://{bucket}/{import_name}\", usecols=[\"notes\", \"notes_id\"]) #, nrows=1000)\n",
    "    text.notes_id = text.notes_id.astype(str)\n",
    "    text = text.drop_duplicates(subset=[\"notes_id\"]).reset_index(drop=True)\n",
    "    text = text.rename(columns={\"notes\":\"text\"})\n",
    "\n",
    "ltext = list(text[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0ee22-506e-4fc3-9fd2-9d21aab8bd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "divide = 700\n",
    "start = 0\n",
    "itn = 0\n",
    "\n",
    "while start < len(text):\n",
    "    text_df = text.iloc[start:start+divide,].copy()\n",
    "    text_df.iteritems = text_df.items\n",
    "    text_df = spark.createDataFrame(data=text_df)\n",
    "    light_result_dif = model_difdetect.transform(text_df)\n",
    "    lr_df = light_result_dif.toPandas()\n",
    "\n",
    "    begin = []\n",
    "    end = []\n",
    "    length = []\n",
    "    chunk = []\n",
    "    entity = []\n",
    "    status = []\n",
    "    confidence = []\n",
    "    notes_id = []\n",
    "    \n",
    "    def get_info(row):\n",
    "        for i in range(len(row.assertion)):\n",
    "            begin.append(row.ner_chunk[i].begin)\n",
    "            end.append(row.ner_chunk[i].end)\n",
    "            length.append(row.ner_chunk[i].end - row.ner_chunk[i].begin)\n",
    "            chunk.append(row.ner_chunk[i].result)\n",
    "            entity.append(row.ner_chunk[i].metadata[\"entity\"])\n",
    "            status.append(row.assertion[i].result)\n",
    "            confidence.append(row.assertion[i].metadata[\"confidence\"])\n",
    "            notes_id.append(row.notes_id)\n",
    "    \n",
    "\n",
    "    lr_df.apply(get_info, axis=1)\n",
    "    pd.set_option('max_colwidth', None)\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "\n",
    "    df = pd.DataFrame({'chunks':chunk, 'chunk_begin':begin, 'chunk_end': end, 'chunk_len': length,\n",
    "                         'entities':entity, 'assertion':status, 'confidence':confidence, 'notes_id':notes_id})\n",
    "    \n",
    "\n",
    "    df.to_csv(f\"s3://{bucket}/{export_name}_{itn}.csv\")\n",
    "    del df\n",
    "\n",
    "    lrdn = light_result_dif.select(\"token.result\", \"token.begin\", \"token.end\", \"clinical_ner.result\", \n",
    "                                       \"wip_ner.result\", \"bert_ner.result\", \"notes_id\")\n",
    "    lrdn = lrdn.toDF(\"token\", \"token.begin\", \"token.end\", \"clinical_ner\",\n",
    "                      \"wip_ner\", \"bert_ner\", \"notes_id\")\n",
    "\n",
    "    pd_df = lrdn.toPandas()\n",
    "    pd_df.to_csv(f\"s3://{bucket}/{export_name}_{itn}_tok.csv\")\n",
    "    itn += 1\n",
    "    start += divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f595b-1d2b-4fa1-b50e-317ef01c25b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conc = []\n",
    "for n in range(0, itn):\n",
    "    conc.append(pd.read_csv(f\"s3://{bucket}/{export_name}_{n}.csv\"))\n",
    "\n",
    "if len(conc) > 1:\n",
    "    conc = pd.concat(conc).reset_index(drop=True)\n",
    "else:\n",
    "    conc = conc[0]\n",
    "    \n",
    "conc = conc[['chunks', 'chunk_begin', 'chunk_end', 'chunk_len', 'entities', 'assertion', 'confidence', 'notes_id']]\n",
    "conc.to_csv(f\"s3://{bucket}/{export_name}_assertions.csv\", index=False)\n",
    "del conc\n",
    "for n in range(0, itn):\n",
    "    #clean up\n",
    "    s3_client.delete_object(Bucket=bucket, Key=export_name + \"_\" + str(n) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42c1dc-022e-4280-93bd-cb3967965943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_df = []\n",
    "for n in range(0, itn):\n",
    "    pd_df.append(pd.read_csv(f\"s3://{bucket}/{export_name}_{n}_tok.csv\"))\n",
    "if len(pd_df) > 1:\n",
    "    pd_df = pd.concat(pd_df).reset_index(drop=True)\n",
    "else:\n",
    "    pd_df = pd_df[0]    \n",
    "\n",
    "#Clean up/re-listify various columns\n",
    "pd_df = pd_df[pd_df[\"token.begin\"] != '[]']\n",
    "pd_df = pd_df[pd_df[\"token.end\"] != '[]']\n",
    "pd_df[\"token.begin\"] = pd_df[\"token.begin\"].apply(lambda x: [int(i) for i in x[1:-1].split(', ') if i != ''])\n",
    "pd_df[\"token.end\"] = pd_df[\"token.end\"].apply(lambda x: [int(i) for i in x[1:-1].split(', ') if i != ''])\n",
    "pd_df[\"token\"] = pd_df[\"token\"].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))\n",
    "pd_df[\"clinical_ner\"] = pd_df[\"clinical_ner\"].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))\n",
    "pd_df[\"wip_ner\"] = pd_df[\"wip_ner\"].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))\n",
    "pd_df[\"bert_ner\"] = pd_df[\"bert_ner\"].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))\n",
    "pd_df = pd_df[pd_df[\"token.begin\"].map(len) > 0]\n",
    "pd_df = pd_df[pd_df[\"token.end\"].map(len) > 0]\n",
    "\n",
    "#Finalize columns\n",
    "pd_df = pd_df.reset_index()\n",
    "pd_df = pd_df[[\"index\", \"token\", \"token.begin\", \"token.end\",\n",
    "               \"clinical_ner\", \"wip_ner\", \"bert_ner\", \"notes_id\"]]\n",
    "pd_df = pd_df.set_axis([\"note_no\", \"tokens\", \"token_start\", \"token_end\",\n",
    "                        \"clinical_ner\", \"wip_ner\", \"BERT_ner\", \"notes_id\"], axis=1)\n",
    "pd_df[\"note_no\"] = pd_df[\"note_no\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f23687-803b-4c7c-9c9d-ac7ed2942c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explode df\n",
    "cons = []\n",
    "\n",
    "def match_tokens(row):\n",
    "    tokens = list(zip(row.tokens, row.token_start, row.token_end,\n",
    "                       row.clinical_ner, row.wip_ner, row.BERT_ner))\n",
    "    out = pd.DataFrame(tokens, columns=[\"tokens\", \"token_start\", \"token_end\",\n",
    "                                        \"clinical_ner\", \"wip_ner\", \"BERT_ner\"])\n",
    "    out[\"note_no\"] = row.note_no\n",
    "    out[\"notes_id\"] = row.notes_id\n",
    "    cons.append(out)\n",
    "\n",
    "pd_df = pd_df.apply(match_tokens, axis=1)\n",
    "del pd_df\n",
    "exploded_df = pd.concat(cons)\n",
    "exploded_df[\"token_len\"] = (exploded_df.token_end - exploded_df.token_start) + 1\n",
    "exploded_df = exploded_df[[\"tokens\", \"token_start\", \"token_end\", \"token_len\",\n",
    "                          \"clinical_ner\", \"wip_ner\", \"BERT_ner\", \"notes_id\", \"note_no\"]]\n",
    "exploded_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442f016-07a6-4ae8-b5c3-808f555a6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df.to_csv((f\"s3://{bucket}/{export_name}_tokens.csv\"), index=False)\n",
    "for n in range(0, itn):\n",
    "    #clean up\n",
    "    s3_client.delete_object(Bucket=bucket, Key=export_name + \"_\" + str(n) + \"_tok.csv\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "NLP RECOVER",
   "language": "python",
   "name": "nlprecover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
